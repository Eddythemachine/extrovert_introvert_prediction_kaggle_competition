{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQQXUrXtkfHB"
      },
      "source": [
        "# IMPORTING LIB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxRQmflu5669",
        "outputId": "014148ba-0562-45ae-943e-0f16e9af5c6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.6.1)\n",
            "Collecting xgboost (from -r requirements.txt (line 6))\n",
            "  Downloading xgboost-3.0.3-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting lightgbm (from -r requirements.txt (line 7))\n",
            "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (3.6.0)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_nccl_cu12-2.27.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n",
            "Downloading xgboost-3.0.3-py3-none-manylinux_2_28_x86_64.whl (253.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.8/253.8 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.5/322.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost, lightgbm\n",
            "Successfully installed lightgbm-4.6.0 nvidia-nccl-cu12-2.27.6 xgboost-3.0.3\n"
          ]
        }
      ],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tjRzvyRo6Sl0"
      },
      "outputs": [],
      "source": [
        "# Standard library\n",
        "import pickle\n",
        "\n",
        "# Data manipulation\n",
        "import pandas as pd\n",
        "\n",
        "# Scikit-learn modules\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Boosting libraries\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScZ41zSPkXSg"
      },
      "source": [
        "# IMPORTING DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIwvBLw361uC"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jPnD7sIJ6ns6"
      },
      "outputs": [],
      "source": [
        "# Load Data\n",
        "train_df = pd.read_csv('train_processed.csv')\n",
        "val_df = pd.read_csv('val_processed.csv')\n",
        "test_df = pd.read_csv('test_processed.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "61wsNsPm6zH2"
      },
      "outputs": [],
      "source": [
        "# Load Encoders\n",
        "with open('preprocessing_pipeline.pkl', 'rb') as f:\n",
        "    pipeline_objects = pickle.load(f)\n",
        "label_encoders = pipeline_objects['label_encoders']\n",
        "le_y = label_encoders['Personality']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ubEKxgIY6-8E"
      },
      "outputs": [],
      "source": [
        "# Split train/val\n",
        "X_train = train_df.drop(columns='Personality')\n",
        "y_train = le_y.transform(train_df['Personality'])\n",
        "\n",
        "X_val = val_df.drop(columns='Personality')\n",
        "y_val = le_y.transform(val_df['Personality'])\n",
        "\n",
        "X_test = test_df.drop(columns='id')\n",
        "test_ids = test_df['id']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcwGD1q77EVV"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH7i-Mhz7fMN"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lh6jDU5I7DJ-"
      },
      "outputs": [],
      "source": [
        "# Define candidate models\n",
        "models = {\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'GradientBoosting': GradientBoostingClassifier(),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
        "    'SVC': SVC(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
        "    'LightGBM': LGBMClassifier()\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90BvSN6p7hkL"
      },
      "source": [
        "### Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5ZoqIvrG7cIt"
      },
      "outputs": [],
      "source": [
        "# Add stacking ensemble\n",
        "models['Stacking'] = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss')),\n",
        "        ('lgbm', LGBMClassifier())\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(),\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIR0gy617roi",
        "outputId": "8107c1f8-56e3-4d70-decb-180af73380d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForest Accuracy: 0.9698\n",
            "GradientBoosting Accuracy: 0.9719\n",
            "LogisticRegression Accuracy: 0.9717\n",
            "SVC Accuracy: 0.9719\n",
            "KNN Accuracy: 0.9714\n",
            "XGBoost Accuracy: 0.9717\n",
            "[LightGBM] [Info] Number of positive: 3860, number of negative: 10959\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000789 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 244\n",
            "[LightGBM] [Info] Number of data points in the train set: 14819, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.260476 -> initscore=-1.043494\n",
            "[LightGBM] [Info] Start training from score -1.043494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [05:46:12] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM Accuracy: 0.9719\n",
            "Stacking Accuracy: 0.9722\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate all models\n",
        "accuracies = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_val)\n",
        "    acc = accuracy_score(y_val, preds)\n",
        "    accuracies[name] = acc\n",
        "    print(f\"{name} Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6glVPdkX7uPQ",
        "outputId": "d0a36f36-68b2-4804-a7e0-c87466711a5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… Best Model (Before Tuning): Stacking\n"
          ]
        }
      ],
      "source": [
        "# Select best model\n",
        "best_model_name = max(accuracies, key=accuracies.get)\n",
        "best_model = models[best_model_name]\n",
        "print(f\"\\nâœ… Best Model (Before Tuning): {best_model_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Pj8QBKCf70fo"
      },
      "outputs": [],
      "source": [
        "# Define tuning grid\n",
        "param_grid = {}\n",
        "if best_model_name == 'RandomForest':\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [None, 10, 20]\n",
        "    }\n",
        "elif best_model_name == 'GradientBoosting':\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'learning_rate': [0.05, 0.1]\n",
        "    }\n",
        "elif best_model_name == 'LogisticRegression':\n",
        "    param_grid = {'C': [0.1, 1.0, 10.0]}\n",
        "elif best_model_name == 'SVC':\n",
        "    param_grid = {'C': [0.1, 1.0], 'kernel': ['linear', 'rbf']}\n",
        "elif best_model_name == 'KNN':\n",
        "    param_grid = {'n_neighbors': [3, 5, 7]}\n",
        "elif best_model_name == 'XGBoost':\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'learning_rate': [0.05, 0.1],\n",
        "        'max_depth': [3, 5, 7]\n",
        "    }\n",
        "elif best_model_name == 'LightGBM':\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'learning_rate': [0.05, 0.1],\n",
        "        'num_leaves': [15, 31]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bABiwJ8n73gv",
        "outputId": "33d92c57-bc46-4e26-bc57-5ff4984039eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Tune with RandomizedSearch\n",
        "search = RandomizedSearchCV(\n",
        "    best_model,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "search.fit(X_train, y_train)\n",
        "final_tuned_model = search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zg19okd75N5",
        "outputId": "344ddef0-4801-4b27-e2ee-8708cfa9d54f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… Tuned Stacking Validation Accuracy: 0.9722\n",
            "ðŸ“Œ Best Hyperparameters: {}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate tuned model on val set\n",
        "val_preds = final_tuned_model.predict(X_val)\n",
        "val_acc = accuracy_score(y_val, val_preds)\n",
        "print(f\"\\nâœ… Tuned {best_model_name} Validation Accuracy: {val_acc:.4f}\")\n",
        "print(f\"ðŸ“Œ Best Hyperparameters: {search.best_params_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceRpgs9K75z5",
        "outputId": "68d67956-9511-4b95-fd37-36e1e647e5f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŽ¯ Final model retrained on full dataset.\n"
          ]
        }
      ],
      "source": [
        "# Retrain on full (train + val)\n",
        "full_df = pd.concat([train_df, val_df], ignore_index=True)\n",
        "X_full = full_df.drop(columns='Personality')\n",
        "y_full = le_y.transform(full_df['Personality'])\n",
        "\n",
        "final_tuned_model.fit(X_full, y_full)\n",
        "print(\"ðŸŽ¯ Final model retrained on full dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El9N6__a8AQ7",
        "outputId": "611b6c00-c947-485a-a5e0-e82c15efa41f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Final model saved as 'final_full_model.pkl'.\n"
          ]
        }
      ],
      "source": [
        "# Save full-data model\n",
        "with open('../model/modelling/final_full_model.pkl', 'wb') as f:\n",
        "    pickle.dump(final_tuned_model, f)\n",
        "print(\"âœ… Final model saved as 'final_full_model.pkl'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "D_aMGSTw8CO1"
      },
      "outputs": [],
      "source": [
        "# Predict and decode test set\n",
        "full_test_preds = final_tuned_model.predict(X_test)\n",
        "decoded_preds = le_y.inverse_transform(full_test_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv3ABfGHVea6",
        "outputId": "91084ba9-93f6-46a2-bf87-2f84c7e78950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“„ New submission saved as 'submission_full.csv'.\n"
          ]
        }
      ],
      "source": [
        "# Save new submission file\n",
        "submission_full = pd.DataFrame({\n",
        "    'id': test_ids,\n",
        "    'Personality': decoded_preds\n",
        "})\n",
        "submission_full.to_csv('../data/submission/submission_full.csv', index=False)\n",
        "print(\"ðŸ“„ New submission saved as 'submission_full.csv'.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
